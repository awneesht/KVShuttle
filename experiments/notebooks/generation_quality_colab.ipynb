{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# KVShuttle: FP16 Generation Quality on GPU\n\nThis notebook runs the end-to-end generation quality experiment using\nFP16 PyTorch models on a CUDA GPU (T4/A100).\n\n**Smoke test mode:** qwen2.5-3b only, 5 prompts (~5-10 min on T4).\nChange `CONFIG` below to run the full experiment.\n\n## Setup\nCreate the zip locally first:\n```bash\ncd /path/to/KVShuttle\nzip -r kvshuttle.zip . -x '.git/*'\n```\nThen upload when prompted in the install cell below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"No GPU detected! Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q transformers accelerate datasets pyyaml tqdm\n\n# Upload kvshuttle.zip (created locally via: cd KVShuttle && zip -r kvshuttle.zip . -x '.git/*')\nimport os\nif not os.path.exists(\"kvshuttle\"):\n    from google.colab import files\n    print(\"Upload kvshuttle.zip (see instructions in markdown above)\")\n    uploaded = files.upload()  # upload kvshuttle.zip\n    !unzip -qo kvshuttle.zip -d KVShuttle\n    %cd KVShuttle\n    !pip install -q -e .\nelse:\n    print(\"KVShuttle already installed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify KVShuttle installation and torch backend\n",
    "from kvshuttle.models.loader_torch import TORCH_MODEL_REGISTRY, load_model_torch\n",
    "from kvshuttle.models.kv_extractor_torch import extract_kv_cache_torch\n",
    "from kvshuttle.models.kv_injector_torch import forward_continuation_with_kv_cache_torch\n",
    "from kvshuttle.compression.registry import list_compressors\n",
    "\n",
    "print(f\"Available models: {list(TORCH_MODEL_REGISTRY.keys())}\")\n",
    "print(f\"Available compressors: {list_compressors()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Run the experiment\n\nSet `CONFIG` to choose between smoke test (quick) and full run."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choose config: smoke test (qwen2.5-3b, 5 prompts) or full (3 models, 50 prompts)\n# CONFIG = \"experiments/configs/generation_quality_torch_smoke.yaml\"  # ~5-10 min on T4\nCONFIG = \"experiments/configs/generation_quality_torch.yaml\"          # ~2-3 hrs on T4\n\n!python -m experiments.scripts.run_experiment {CONFIG}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect results\nimport json\nfrom pathlib import Path\n\n# Auto-detect results dir from config\nresults_dirs = [\n    Path(\"experiments/results/generation_quality_fp16_smoke\"),\n    Path(\"experiments/results/generation_quality_fp16\"),\n]\nresults_path = next((d / \"results.json\" for d in results_dirs if (d / \"results.json\").exists()), None)\n\nif results_path:\n    with open(results_path) as f:\n        data = json.load(f)\n    print(f\"Metadata: {json.dumps(data['metadata'], indent=2)}\")\n    print(f\"\\nTotal results: {len(data['results'])}\")\n    \n    import pandas as pd\n    df = pd.DataFrame(data['results'])\n    print(f\"\\nAvailable columns: {list(df.columns)}\")\n    \n    # Aggregate only columns that exist\n    agg_cols = {}\n    for col in ['mean_key_cosine_sim', 'perplexity_delta', 'token_agreement']:\n        if col in df.columns:\n            agg_cols[col] = 'mean'\n    \n    if agg_cols:\n        summary = df.groupby(['model', 'compressor']).agg(agg_cols).round(4)\n        display(summary)\n    else:\n        print(\"\\nNo quality metrics found â€” check WARNING logs above for errors\")\nelse:\n    print(\"Results not found. Check experiment output above for errors.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download results for local figure generation\nif results_path and results_path.exists():\n    from google.colab import files\n    files.download(str(results_path))\n    print(f\"Downloaded {results_path}\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}