{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# KVShuttle: GPU-Native Compression Calibration (Zero-Copy)\n\nThis notebook measures the **true GPU kernel time** for KV cache compression by:\n1. Pre-loading all data to GPU memory before timing starts\n2. Running compression entirely on GPU tensors (no numpy round-trips)\n3. Using `torch.cuda.Event` for microsecond-precision GPU timing\n\nThis eliminates the CPU↔GPU copy overhead that dominated the v1 results (1.5x speedup).\nThe goal is to measure what a real production system (vLLM, TRT-LLM) would achieve.\n\n---\n\n## GPU Runtime Options\n\n| GPU | Colab Tier | Est. Runtime | Notes |\n|-----|-----------|-------------|-------|\n| **T4** (16 GB) | Free | ~15-25 min | Baseline. Seq ≤ 2048 only |\n| **A100** (40/80 GB) | Pro+ | ~5-10 min | Adds seq 4096 + large models |\n| **H100** (80 GB) | Enterprise / self-hosted | ~3-7 min | Native FP8, adds high-BW tests |\n\n**Instructions**:\n1. Runtime > Change runtime type > Select your GPU\n2. Run All\n3. Download `gpu_calibration_results_{gpu_tier}.json` from the file browser\n4. To combine results from multiple GPUs, see the last cell",
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Check GPU and setup\nimport torch\nimport numpy as np\nimport time\nimport json\nimport statistics\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    props = torch.cuda.get_device_properties(0)\n    vram_gb = props.total_mem / 1e9\n    print(f\"GPU: {gpu_name}\")\n    print(f\"VRAM: {vram_gb:.1f} GB\")\n    device = torch.device(\"cuda\")\n\n    # Detect GPU tier\n    gpu_name_lower = gpu_name.lower()\n    if \"h100\" in gpu_name_lower:\n        GPU_TIER = \"h100\"\n    elif \"a100\" in gpu_name_lower:\n        GPU_TIER = \"a100\"\n    elif \"l4\" in gpu_name_lower:\n        GPU_TIER = \"l4\"\n    else:\n        GPU_TIER = \"t4\"\n    print(f\"Detected GPU tier: {GPU_TIER}\")\n\n    # Memory bandwidth lookup (GB/s) for metadata\n    MEMORY_BW_LOOKUP = {\n        \"t4\": 320,\n        \"l4\": 300,\n        \"a100\": 2039,\n        \"h100\": 3350,\n    }\n\n    # Collect GPU properties for multi-GPU comparison\n    gpu_info = {\n        \"name\": gpu_name,\n        \"gpu_tier\": GPU_TIER,\n        \"compute_capability\": f\"{props.major}.{props.minor}\",\n        \"total_memory_gb\": round(vram_gb, 1),\n        \"memory_bandwidth_gbps\": MEMORY_BW_LOOKUP.get(GPU_TIER, 0),\n        \"multi_processor_count\": props.multi_processor_count,\n        \"cuda_version\": torch.version.cuda,\n        \"pytorch_version\": torch.__version__,\n    }\n    print(f\"Compute capability: {gpu_info['compute_capability']}\")\n    print(f\"SMs: {gpu_info['multi_processor_count']}\")\n    print(f\"Memory bandwidth: {gpu_info['memory_bandwidth_gbps']} GB/s\")\n    print(f\"CUDA: {gpu_info['cuda_version']}\")\nelse:\n    print(\"WARNING: No CUDA GPU! Go to Runtime > Change runtime type > T4 GPU\")\n    gpu_name = \"CPU\"\n    GPU_TIER = \"cpu\"\n    gpu_info = {\"name\": \"CPU\", \"gpu_tier\": \"cpu\"}\n    device = torch.device(\"cpu\")\n\n# Config — adaptive based on GPU tier\nMODELS = {\n    \"llama-3.2-3b\": (28, 8, 128),\n    \"qwen2.5-7b\":   (28, 4, 128),\n    \"llama-3.1-8b\": (32, 8, 128),\n    \"phi-3.5-mini\":  (32, 32, 96),\n}\n\n# Add larger models when VRAM permits\nif torch.cuda.is_available() and vram_gb >= 70:\n    MODELS[\"llama-3.1-70b\"] = (80, 8, 128)\n    print(f\"Added llama-3.1-70b config (VRAM={vram_gb:.0f} GB >= 70 GB)\")\n\n# Sequence lengths — add 4096 on high-VRAM GPUs\nSEQ_LENS = [256, 512, 1024, 2048]\nif torch.cuda.is_available() and vram_gb >= 40:\n    SEQ_LENS.append(4096)\n    print(f\"Added seq_len=4096 (VRAM={vram_gb:.0f} GB >= 40 GB)\")\n\n# Bandwidth test range — add high-BW points for H100 NVLink\nBANDWIDTHS_GBPS = [1, 5, 10, 25, 50, 100, 200, 400]\nif GPU_TIER == \"h100\":\n    BANDWIDTHS_GBPS.extend([800, 1600])\n    print(f\"Added 800/1600 Gbps bandwidth points for H100 NVLink\")\n\nWARMUP = 5\n\n# More repeats on faster GPUs for stable measurements\nif GPU_TIER in (\"a100\", \"h100\"):\n    REPEATS = 50\n    print(f\"Using REPEATS={REPEATS} (faster kernels need more samples)\")\nelse:\n    REPEATS = 20\n\nprint(f\"\\nConfig: {len(MODELS)} models, seq_lens={SEQ_LENS}, \"\n      f\"bandwidths={BANDWIDTHS_GBPS}, repeats={REPEATS}\")",
   "id": "cell-1",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: GPU-Native Compressor Kernels (Zero-Copy)\n",
    "\n",
    "These functions operate **entirely on GPU tensors**. No numpy, no CPU↔GPU copies.\n",
    "This is what runs inside a real serving system where KV cache lives on GPU."
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: GPU-native INT8 quantization (zero-copy)\n",
    "\n",
    "def gpu_int8_compress(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Per-layer symmetric INT8 quantization. Input/output stay on GPU.\"\"\"\n",
    "    qmax = 127\n",
    "    num_layers = x.shape[0]\n",
    "    flat = x.reshape(num_layers, -1)\n",
    "    amax = flat.abs().amax(dim=1)\n",
    "    amax = torch.where(amax == 0, torch.ones_like(amax), amax)\n",
    "    scales = amax / qmax\n",
    "    scales_exp = scales.view(num_layers, *([1] * (x.ndim - 1)))\n",
    "    quantized = (x / scales_exp).round().clamp(-qmax, qmax).to(torch.int8)\n",
    "    return quantized, scales\n",
    "\n",
    "def gpu_int8_decompress(quantized: torch.Tensor, scales: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Dequantize INT8 → FP16. Input/output stay on GPU.\"\"\"\n",
    "    num_layers = quantized.shape[0]\n",
    "    s_exp = scales.view(num_layers, *([1] * (quantized.ndim - 1)))\n",
    "    return (quantized.float() * s_exp).half()\n",
    "\n",
    "print(\"GPU-native INT8 defined.\")"
   ],
   "id": "cell-3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: GPU-native KIVI 2-bit (zero-copy)\n",
    "\n",
    "def gpu_kivi_compress_keys(x: torch.Tensor, qmax: int = 3):\n",
    "    \"\"\"Per-channel 2-bit quant for keys (along seq_len dim=2). All on GPU.\"\"\"\n",
    "    tmin = x.amin(dim=2)\n",
    "    tmax = x.amax(dim=2)\n",
    "    rng = tmax - tmin\n",
    "    rng = torch.where(rng == 0, torch.ones_like(rng), rng)\n",
    "    scales = rng / qmax\n",
    "    zeros = tmin\n",
    "    quantized = ((x - zeros.unsqueeze(2)) / scales.unsqueeze(2)).round().clamp(0, qmax).to(torch.uint8)\n",
    "    return quantized, scales, zeros\n",
    "\n",
    "def gpu_kivi_compress_values(x: torch.Tensor, qmax: int = 3):\n",
    "    \"\"\"Per-token 2-bit quant for values (along head_dim dim=3). All on GPU.\"\"\"\n",
    "    tmin = x.amin(dim=3)\n",
    "    tmax = x.amax(dim=3)\n",
    "    rng = tmax - tmin\n",
    "    rng = torch.where(rng == 0, torch.ones_like(rng), rng)\n",
    "    scales = rng / qmax\n",
    "    zeros = tmin\n",
    "    quantized = ((x - zeros.unsqueeze(3)) / scales.unsqueeze(3)).round().clamp(0, qmax).to(torch.uint8)\n",
    "    return quantized, scales, zeros\n",
    "\n",
    "def gpu_kivi_decompress_keys(quantized, scales, zeros):\n",
    "    return (quantized.float() * scales.unsqueeze(2) + zeros.unsqueeze(2)).half()\n",
    "\n",
    "def gpu_kivi_decompress_values(quantized, scales, zeros):\n",
    "    return (quantized.float() * scales.unsqueeze(3) + zeros.unsqueeze(3)).half()\n",
    "\n",
    "print(\"GPU-native KIVI 2-bit defined.\")"
   ],
   "id": "cell-4",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3b: GPU-native INT4 per-group quantization (zero-copy)\n",
    "\n",
    "def gpu_int4_compress(x, group_size=128):\n",
    "    \"\"\"Per-group asymmetric INT4 quantization. Packs 2 values per byte on GPU.\"\"\"\n",
    "    original_shape = list(x.shape)\n",
    "    flat = x.reshape(-1)\n",
    "    n = flat.numel()\n",
    "    padded_len = ((n + group_size - 1) // group_size) * group_size\n",
    "    if padded_len > n:\n",
    "        flat = torch.nn.functional.pad(flat, (0, padded_len - n))\n",
    "    grouped = flat.reshape(-1, group_size)\n",
    "    gmin = grouped.amin(dim=1)\n",
    "    gmax = grouped.amax(dim=1)\n",
    "    rng = gmax - gmin\n",
    "    rng = torch.where(rng == 0, torch.ones_like(rng), rng)\n",
    "    scales = rng / 15.0\n",
    "    zeros = gmin\n",
    "    quantized = ((grouped - zeros.unsqueeze(1)) / scales.unsqueeze(1)).round().clamp(0, 15).to(torch.uint8)\n",
    "    flat_q = quantized.reshape(-1)\n",
    "    if flat_q.numel() % 2 != 0:\n",
    "        flat_q = torch.nn.functional.pad(flat_q, (0, 1))\n",
    "    packed = (flat_q[0::2] << 4) | flat_q[1::2]\n",
    "    return packed, scales, zeros, original_shape\n",
    "\n",
    "def gpu_int4_decompress(packed, scales, zeros, original_shape, group_size=128):\n",
    "    \"\"\"Dequantize packed INT4 back to float16 on GPU.\"\"\"\n",
    "    high = (packed >> 4) & 0x0F\n",
    "    low = packed & 0x0F\n",
    "    flat_q = torch.empty(packed.numel() * 2, dtype=torch.uint8, device=packed.device)\n",
    "    flat_q[0::2] = high\n",
    "    flat_q[1::2] = low\n",
    "    total_elements = 1\n",
    "    for s in original_shape:\n",
    "        total_elements *= s\n",
    "    padded_len = scales.numel() * group_size\n",
    "    grouped = flat_q[:padded_len].reshape(-1, group_size).float()\n",
    "    result = grouped * scales.unsqueeze(1) + zeros.unsqueeze(1)\n",
    "    return result.reshape(-1)[:total_elements].reshape(original_shape).half()\n",
    "\n",
    "print(\"GPU-native INT4 defined.\")"
   ],
   "id": "cell-5",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 3c: GPU-native FP8 E4M3 (native on H100, simulated fallback)\n\n# Detect native FP8 support (PyTorch 2.1+ on Hopper/H100)\nHAS_NATIVE_FP8 = hasattr(torch, \"float8_e4m3fn\")\nif HAS_NATIVE_FP8:\n    try:\n        _test = torch.zeros(1, device=\"cuda\", dtype=torch.float8_e4m3fn)\n        del _test\n    except Exception:\n        HAS_NATIVE_FP8 = False\n\nif HAS_NATIVE_FP8:\n    print(\"Using NATIVE FP8 E4M3 (torch.float8_e4m3fn) — H100 Hopper path\")\n\n    def gpu_fp8_compress(x):\n        \"\"\"Native FP8 E4M3: per-layer scale, cast to torch.float8_e4m3fn.\"\"\"\n        num_layers = x.shape[0]\n        flat = x.reshape(num_layers, -1)\n        amax = flat.abs().amax(dim=1)\n        amax = torch.where(amax == 0, torch.ones_like(amax), amax)\n        scales = amax / torch.finfo(torch.float8_e4m3fn).max\n        scales_exp = scales.view(num_layers, *([1] * (x.ndim - 1)))\n        quantized = (x / scales_exp).to(torch.float8_e4m3fn)\n        return quantized, scales\n\n    def gpu_fp8_decompress(quantized, scales):\n        \"\"\"Dequantize native FP8 back to float16.\"\"\"\n        num_layers = quantized.shape[0]\n        s_exp = scales.view(num_layers, *([1] * (quantized.ndim - 1)))\n        return (quantized.float() * s_exp).half()\nelse:\n    print(\"Using SIMULATED FP8 E4M3 (uint8 fallback) — T4/A100 path\")\n\n    def gpu_fp8_compress(x):\n        \"\"\"Simulated FP8 E4M3: per-layer scale = amax/240, quantize to uint8.\"\"\"\n        num_layers = x.shape[0]\n        flat = x.reshape(num_layers, -1)\n        amax = flat.abs().amax(dim=1)\n        amax = torch.where(amax == 0, torch.ones_like(amax), amax)\n        scales = amax / 240.0\n        scales_exp = scales.view(num_layers, *([1] * (x.ndim - 1)))\n        quantized = (x / scales_exp + 128.0).round().clamp(0, 255).to(torch.uint8)\n        return quantized, scales\n\n    def gpu_fp8_decompress(quantized, scales):\n        \"\"\"Dequantize simulated FP8 back to float16.\"\"\"\n        num_layers = quantized.shape[0]\n        s_exp = scales.view(num_layers, *([1] * (quantized.ndim - 1)))\n        return ((quantized.float() - 128.0) * s_exp).half()\n\nFP8_PATH = \"native\" if HAS_NATIVE_FP8 else \"simulated\"\nprint(f\"GPU-native FP8 E4M3 defined (path={FP8_PATH}).\")",
   "id": "cell-6",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3d: GPU-native CacheGen (anchor INT8 + delta INT4, chunked)\n",
    "\n",
    "def gpu_cachegen_compress(x, chunk_size=10):\n",
    "    \"\"\"CacheGen: anchor tokens (INT8) + delta tokens (INT4 packed). All on GPU.\"\"\"\n",
    "    original_shape = list(x.shape)\n",
    "    L, H, S, D = x.shape\n",
    "    N = L * H\n",
    "    flat = x.reshape(N, S, D)\n",
    "    num_chunks = (S + chunk_size - 1) // chunk_size\n",
    "\n",
    "    anchor_indices = torch.arange(0, S, chunk_size, device=x.device)\n",
    "    anchors = flat[:, anchor_indices, :]\n",
    "\n",
    "    a_flat = anchors.reshape(N * num_chunks, D)\n",
    "    a_min = a_flat.amin(dim=1, keepdim=True)\n",
    "    a_max = a_flat.amax(dim=1, keepdim=True)\n",
    "    a_rng = a_max - a_min\n",
    "    a_rng = torch.where(a_rng == 0, torch.ones_like(a_rng), a_rng)\n",
    "    a_scales = (a_rng / 255.0).squeeze(1)\n",
    "    a_zeros = a_min.squeeze(1)\n",
    "    a_quant = ((a_flat - a_zeros.unsqueeze(1)) / a_scales.unsqueeze(1)).round().clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "    anchors_expanded = torch.zeros_like(flat)\n",
    "    for c in range(num_chunks):\n",
    "        start = c * chunk_size\n",
    "        end = min(start + chunk_size, S)\n",
    "        anchors_expanded[:, start:end, :] = anchors[:, c:c+1, :]\n",
    "\n",
    "    all_indices = torch.arange(S, device=x.device)\n",
    "    delta_mask = (all_indices % chunk_size) != 0\n",
    "    delta_indices = all_indices[delta_mask]\n",
    "    deltas = flat[:, delta_indices, :] - anchors_expanded[:, delta_indices, :]\n",
    "\n",
    "    d_flat = deltas.reshape(-1, D)\n",
    "    d_min = d_flat.amin(dim=1, keepdim=True)\n",
    "    d_max = d_flat.amax(dim=1, keepdim=True)\n",
    "    d_rng = d_max - d_min\n",
    "    d_rng = torch.where(d_rng == 0, torch.ones_like(d_rng), d_rng)\n",
    "    d_scales = (d_rng / 15.0).squeeze(1)\n",
    "    d_zeros = d_min.squeeze(1)\n",
    "    d_quant = ((d_flat - d_zeros.unsqueeze(1)) / d_scales.unsqueeze(1)).round().clamp(0, 15).to(torch.uint8)\n",
    "\n",
    "    d_flat_q = d_quant.reshape(-1)\n",
    "    if d_flat_q.numel() % 2 != 0:\n",
    "        d_flat_q = torch.nn.functional.pad(d_flat_q, (0, 1))\n",
    "    delta_packed = (d_flat_q[0::2] << 4) | d_flat_q[1::2]\n",
    "\n",
    "    return a_quant, a_scales, a_zeros, delta_packed, d_scales, d_zeros, original_shape\n",
    "\n",
    "def gpu_cachegen_decompress(a_quant, a_scales, a_zeros, delta_packed, d_scales, d_zeros, original_shape, chunk_size=10):\n",
    "    \"\"\"Decompress CacheGen anchor+delta on GPU.\"\"\"\n",
    "    L, H, S, D = original_shape\n",
    "    N = L * H\n",
    "    num_chunks = (S + chunk_size - 1) // chunk_size\n",
    "\n",
    "    anchors = (a_quant.float() * a_scales.unsqueeze(1) + a_zeros.unsqueeze(1))\n",
    "    anchors = anchors.reshape(N, num_chunks, D)\n",
    "\n",
    "    high = (delta_packed >> 4) & 0x0F\n",
    "    low = delta_packed & 0x0F\n",
    "    d_unpacked = torch.empty(delta_packed.numel() * 2, dtype=torch.uint8, device=delta_packed.device)\n",
    "    d_unpacked[0::2] = high\n",
    "    d_unpacked[1::2] = low\n",
    "\n",
    "    all_indices = torch.arange(S, device=a_quant.device)\n",
    "    num_delta_tokens = int((all_indices % chunk_size != 0).sum().item())\n",
    "    total_delta_elements = N * num_delta_tokens * D\n",
    "    d_flat = d_unpacked[:total_delta_elements].reshape(-1, D).float()\n",
    "\n",
    "    deltas = d_flat * d_scales[:d_flat.shape[0]].unsqueeze(1) + d_zeros[:d_flat.shape[0]].unsqueeze(1)\n",
    "    deltas = deltas.reshape(N, num_delta_tokens, D)\n",
    "\n",
    "    result = torch.zeros(N, S, D, device=a_quant.device, dtype=torch.float32)\n",
    "    anchor_positions = torch.arange(0, S, chunk_size, device=a_quant.device)\n",
    "    result[:, anchor_positions, :] = anchors\n",
    "\n",
    "    delta_positions = all_indices[all_indices % chunk_size != 0]\n",
    "    chunk_ids = delta_positions // chunk_size\n",
    "    result[:, delta_positions, :] = deltas + anchors[:, chunk_ids, :]\n",
    "\n",
    "    return result.reshape(original_shape).half()\n",
    "\n",
    "print(\"GPU-native CacheGen defined.\")"
   ],
   "id": "cell-7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3e: GPU-native Cascade (prune 50% + INT4)\n",
    "\n",
    "def gpu_cascade_compress(keys, values, keep_ratio=0.5, group_size=128):\n",
    "    \"\"\"Cascade: prune 50% tokens by key norm importance, then INT4 quantize.\"\"\"\n",
    "    L, H, S, D = keys.shape\n",
    "    keep_count = max(1, int(S * keep_ratio))\n",
    "\n",
    "    key_norms = torch.linalg.norm(keys, dim=3)\n",
    "    importance = key_norms.mean(dim=(0, 1))\n",
    "\n",
    "    protect = min(2, S)\n",
    "    imp_copy = importance.clone()\n",
    "    imp_copy[:protect] = -float('inf')\n",
    "    if S > protect:\n",
    "        imp_copy[max(protect, S - protect):] = -float('inf')\n",
    "\n",
    "    remaining_budget = keep_count - min(2 * protect, S)\n",
    "    if remaining_budget > 0:\n",
    "        _, topk_idx = torch.topk(imp_copy, remaining_budget)\n",
    "    else:\n",
    "        topk_idx = torch.tensor([], dtype=torch.long, device=keys.device)\n",
    "\n",
    "    protected = list(range(protect)) + list(range(max(protect, S - protect), S))\n",
    "    protected_t = torch.tensor(protected, dtype=torch.long, device=keys.device)\n",
    "    keep_indices = torch.sort(torch.cat([protected_t, topk_idx]))[0][:keep_count]\n",
    "\n",
    "    pruned_keys = keys[:, :, keep_indices, :]\n",
    "    pruned_values = values[:, :, keep_indices, :]\n",
    "\n",
    "    k_packed, k_scales, k_zeros, k_shape = gpu_int4_compress(pruned_keys, group_size)\n",
    "    v_packed, v_scales, v_zeros, v_shape = gpu_int4_compress(pruned_values, group_size)\n",
    "\n",
    "    return (k_packed, k_scales, k_zeros, k_shape,\n",
    "            v_packed, v_scales, v_zeros, v_shape,\n",
    "            keep_indices, list(keys.shape))\n",
    "\n",
    "def gpu_cascade_decompress(k_packed, k_scales, k_zeros, k_shape,\n",
    "                           v_packed, v_scales, v_zeros, v_shape,\n",
    "                           keep_indices, original_shape, group_size=128):\n",
    "    \"\"\"Decompress cascade: INT4 decompress then scatter back.\"\"\"\n",
    "    pruned_keys = gpu_int4_decompress(k_packed, k_scales, k_zeros, k_shape, group_size)\n",
    "    pruned_values = gpu_int4_decompress(v_packed, v_scales, v_zeros, v_shape, group_size)\n",
    "    L, H, S, D = original_shape\n",
    "    keys = torch.zeros(L, H, S, D, device=k_packed.device, dtype=torch.float16)\n",
    "    values = torch.zeros(L, H, S, D, device=k_packed.device, dtype=torch.float16)\n",
    "    keys[:, :, keep_indices, :] = pruned_keys\n",
    "    values[:, :, keep_indices, :] = pruned_values\n",
    "    return keys, values\n",
    "\n",
    "print(\"GPU-native Cascade (prune50+INT4) defined.\")"
   ],
   "id": "cell-8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3f: GPU-native Palu (truncated SVD, rank_ratio=0.25)\n",
    "\n",
    "def gpu_palu_compress(x, rank_ratio=0.25):\n",
    "    \"\"\"Truncated SVD: batched over (L*H) slices. Stores US and Vt as float16.\"\"\"\n",
    "    original_shape = list(x.shape)\n",
    "    L, H, S, D = x.shape\n",
    "    rank = max(1, int(min(S, D) * rank_ratio))\n",
    "    N = L * H\n",
    "    mats = x.reshape(N, S, D)\n",
    "    U, Sigma, Vt = torch.linalg.svd(mats, full_matrices=False)\n",
    "    US = U[:, :, :rank] * Sigma[:, None, :rank]\n",
    "    Vt_r = Vt[:, :rank, :]\n",
    "    return US.half(), Vt_r.half(), original_shape, rank\n",
    "\n",
    "def gpu_palu_decompress(US, Vt, original_shape):\n",
    "    \"\"\"Reconstruct from SVD factors via batched matmul.\"\"\"\n",
    "    result = torch.bmm(US.float(), Vt.float())\n",
    "    return result.reshape(original_shape).half()\n",
    "\n",
    "print(\"GPU-native Palu (SVD) defined.\")"
   ],
   "id": "cell-9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 4: CPU numpy compressors (for comparison baseline)\n",
    "\n",
    "def np_int8_compress(tensor: np.ndarray):\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    num_layers = fp32.shape[0]\n",
    "    qmax = 127\n",
    "    scales = np.zeros(num_layers, dtype=np.float32)\n",
    "    quantized = np.zeros(fp32.shape, dtype=np.int8)\n",
    "    for i in range(num_layers):\n",
    "        layer = fp32[i]\n",
    "        amax = np.abs(layer).max()\n",
    "        scales[i] = amax / qmax if amax != 0 else 1.0\n",
    "        quantized[i] = np.clip(np.round(layer / scales[i]), -qmax, qmax).astype(np.int8)\n",
    "    return quantized, scales\n",
    "\n",
    "def np_int8_decompress(quantized, scales):\n",
    "    num_layers = quantized.shape[0]\n",
    "    result = np.zeros(quantized.shape, dtype=np.float32)\n",
    "    for i in range(num_layers):\n",
    "        result[i] = quantized[i].astype(np.float32) * scales[i]\n",
    "    return result.astype(np.float16)\n",
    "\n",
    "def np_kivi_compress_keys(tensor):\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    qmax = 3\n",
    "    tmin = fp32.min(axis=2)\n",
    "    tmax = fp32.max(axis=2)\n",
    "    rng = tmax - tmin\n",
    "    rng[rng == 0] = 1.0\n",
    "    scales = rng / qmax\n",
    "    zeros = tmin\n",
    "    quantized = np.clip(np.round((fp32 - zeros[:,:,np.newaxis,:]) / scales[:,:,np.newaxis,:]), 0, qmax).astype(np.uint8)\n",
    "    return quantized, scales, zeros\n",
    "\n",
    "def np_kivi_compress_values(tensor):\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    qmax = 3\n",
    "    tmin = fp32.min(axis=3)\n",
    "    tmax = fp32.max(axis=3)\n",
    "    rng = tmax - tmin\n",
    "    rng[rng == 0] = 1.0\n",
    "    scales = rng / qmax\n",
    "    zeros = tmin\n",
    "    quantized = np.clip(np.round((fp32 - zeros[:,:,:,np.newaxis]) / scales[:,:,:,np.newaxis]), 0, qmax).astype(np.uint8)\n",
    "    return quantized, scales, zeros\n",
    "\n",
    "def np_kivi_decompress_keys(quant, scales, zeros):\n",
    "    return (quant.astype(np.float32) * scales[:,:,np.newaxis,:] + zeros[:,:,np.newaxis,:]).astype(np.float16)\n",
    "\n",
    "def np_kivi_decompress_values(quant, scales, zeros):\n",
    "    return (quant.astype(np.float32) * scales[:,:,:,np.newaxis] + zeros[:,:,:,np.newaxis]).astype(np.float16)\n",
    "\n",
    "# (INT8 and KIVI baselines above)\n",
    "\n",
    "# --- New CPU baselines for INT4, FP8, CacheGen, Cascade, Palu ---\n",
    "\n",
    "def np_int4_compress(tensor, group_size=128):\n",
    "    \"\"\"CPU INT4 per-group quantization (numpy baseline).\"\"\"\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    flat = fp32.reshape(-1)\n",
    "    padded_len = ((len(flat) + group_size - 1) // group_size) * group_size\n",
    "    padded = np.zeros(padded_len, dtype=np.float32)\n",
    "    padded[:len(flat)] = flat\n",
    "    grouped = padded.reshape(-1, group_size)\n",
    "    gmin = grouped.min(axis=1)\n",
    "    gmax = grouped.max(axis=1)\n",
    "    rng = gmax - gmin\n",
    "    rng[rng == 0] = 1.0\n",
    "    scales = rng / 15.0\n",
    "    zeros = gmin\n",
    "    quantized = np.clip(np.round((grouped - zeros[:, None]) / scales[:, None]), 0, 15).astype(np.uint8)\n",
    "    flat_q = quantized.reshape(-1)\n",
    "    if len(flat_q) % 2 != 0:\n",
    "        flat_q = np.append(flat_q, np.uint8(0))\n",
    "    packed = (flat_q[0::2] << 4) | flat_q[1::2]\n",
    "    return packed, scales, zeros, list(tensor.shape)\n",
    "\n",
    "def np_int4_decompress(packed, scales, zeros, original_shape, group_size=128):\n",
    "    high = (packed >> 4) & 0x0F\n",
    "    low = packed & 0x0F\n",
    "    flat_q = np.empty(len(packed) * 2, dtype=np.uint8)\n",
    "    flat_q[0::2] = high\n",
    "    flat_q[1::2] = low\n",
    "    total = 1\n",
    "    for s in original_shape:\n",
    "        total *= s\n",
    "    padded_len = len(scales) * group_size\n",
    "    grouped = flat_q[:padded_len].reshape(-1, group_size).astype(np.float32)\n",
    "    result = grouped * scales[:, None] + zeros[:, None]\n",
    "    return result.reshape(-1)[:total].reshape(original_shape).astype(np.float16)\n",
    "\n",
    "def np_fp8_compress(tensor):\n",
    "    \"\"\"CPU FP8 E4M3 simulation (numpy baseline).\"\"\"\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    num_layers = fp32.shape[0]\n",
    "    scales = np.zeros(num_layers, dtype=np.float32)\n",
    "    quantized = np.zeros(fp32.shape, dtype=np.uint8)\n",
    "    for i in range(num_layers):\n",
    "        layer = fp32[i]\n",
    "        amax = np.abs(layer).max()\n",
    "        scales[i] = amax / 240.0 if amax != 0 else 1.0\n",
    "        mapped = np.clip(np.round(layer / scales[i] + 128.0), 0, 255)\n",
    "        quantized[i] = mapped.astype(np.uint8)\n",
    "    return quantized, scales\n",
    "\n",
    "def np_fp8_decompress(quantized, scales):\n",
    "    num_layers = quantized.shape[0]\n",
    "    result = np.zeros(quantized.shape, dtype=np.float32)\n",
    "    for i in range(num_layers):\n",
    "        result[i] = (quantized[i].astype(np.float32) - 128.0) * scales[i]\n",
    "    return result.astype(np.float16)\n",
    "\n",
    "def np_cachegen_compress(tensor, chunk_size=10):\n",
    "    \"\"\"CPU CacheGen anchor+delta (numpy baseline).\"\"\"\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    L, H, S, D = fp32.shape\n",
    "    N = L * H\n",
    "    flat = fp32.reshape(N, S, D)\n",
    "    num_chunks = (S + chunk_size - 1) // chunk_size\n",
    "\n",
    "    all_anchors = []\n",
    "    all_deltas = []\n",
    "    for s in range(N):\n",
    "        for c in range(num_chunks):\n",
    "            start = c * chunk_size\n",
    "            end = min(start + chunk_size, S)\n",
    "            anchor = flat[s, start]\n",
    "            all_anchors.append(anchor)\n",
    "            if end - start > 1:\n",
    "                deltas = flat[s, start+1:end] - anchor[None, :]\n",
    "                all_deltas.append(deltas.reshape(-1))\n",
    "\n",
    "    # Simple quantize anchors to uint8 and deltas to int4\n",
    "    a_arr = np.array(all_anchors, dtype=np.float32)\n",
    "    a_min = a_arr.min(axis=1, keepdims=True)\n",
    "    a_max = a_arr.max(axis=1, keepdims=True)\n",
    "    a_rng = a_max - a_min\n",
    "    a_rng[a_rng == 0] = 1.0\n",
    "    a_scales = a_rng / 255.0\n",
    "    a_quant = np.clip(np.round((a_arr - a_min) / a_scales), 0, 255).astype(np.uint8)\n",
    "\n",
    "    if all_deltas:\n",
    "        d_arr = np.concatenate(all_deltas)\n",
    "        d_min = d_arr.min()\n",
    "        d_max = d_arr.max()\n",
    "        d_rng = d_max - d_min if d_max != d_min else 1.0\n",
    "        d_scale = d_rng / 15.0\n",
    "        d_quant = np.clip(np.round((d_arr - d_min) / d_scale), 0, 15).astype(np.uint8)\n",
    "    else:\n",
    "        d_quant = np.array([], dtype=np.uint8)\n",
    "        d_scale = 1.0\n",
    "        d_min = 0.0\n",
    "\n",
    "    return a_quant, a_scales.squeeze(1), a_min.squeeze(1), d_quant, d_scale, d_min, list(tensor.shape)\n",
    "\n",
    "def np_cachegen_decompress(a_quant, a_scales, a_zeros, d_quant, d_scale, d_zero, original_shape, chunk_size=10):\n",
    "    L, H, S, D = original_shape\n",
    "    N = L * H\n",
    "    result = np.zeros((N, S, D), dtype=np.float32)\n",
    "    num_chunks = (S + chunk_size - 1) // chunk_size\n",
    "    a_idx = 0\n",
    "    d_idx = 0\n",
    "    for s in range(N):\n",
    "        for c in range(num_chunks):\n",
    "            start = c * chunk_size\n",
    "            end = min(start + chunk_size, S)\n",
    "            anchor = a_quant[a_idx].astype(np.float32) * a_scales[a_idx] + a_zeros[a_idx]\n",
    "            result[s, start] = anchor\n",
    "            a_idx += 1\n",
    "            if end - start > 1:\n",
    "                n_vals = (end - start - 1) * D\n",
    "                dq = d_quant[d_idx:d_idx+n_vals].astype(np.float32) * d_scale + d_zero\n",
    "                result[s, start+1:end] = anchor[None, :] + dq.reshape(-1, D)\n",
    "                d_idx += n_vals\n",
    "    return result.reshape(original_shape).astype(np.float16)\n",
    "\n",
    "def np_cascade_compress(keys, values, keep_ratio=0.5, group_size=128):\n",
    "    \"\"\"CPU Cascade: prune + INT4 (numpy baseline).\"\"\"\n",
    "    fp32_k = keys.astype(np.float32)\n",
    "    L, H, S, D = fp32_k.shape\n",
    "    keep_count = max(1, int(S * keep_ratio))\n",
    "    key_norms = np.linalg.norm(fp32_k, axis=3).mean(axis=(0, 1))\n",
    "    top_indices = np.argsort(key_norms)[-keep_count:]\n",
    "    keep_indices = np.sort(top_indices)\n",
    "    pruned_k = keys[:, :, keep_indices, :]\n",
    "    pruned_v = values[:, :, keep_indices, :]\n",
    "    kp, ks, kz, ksh = np_int4_compress(pruned_k, group_size)\n",
    "    vp, vs, vz, vsh = np_int4_compress(pruned_v, group_size)\n",
    "    return kp, ks, kz, ksh, vp, vs, vz, vsh, keep_indices, list(keys.shape)\n",
    "\n",
    "def np_cascade_decompress(kp, ks, kz, ksh, vp, vs, vz, vsh, keep_indices, original_shape, group_size=128):\n",
    "    pk = np_int4_decompress(kp, ks, kz, ksh, group_size)\n",
    "    pv = np_int4_decompress(vp, vs, vz, vsh, group_size)\n",
    "    L, H, S, D = original_shape\n",
    "    keys = np.zeros(original_shape, dtype=np.float16)\n",
    "    values = np.zeros(original_shape, dtype=np.float16)\n",
    "    keys[:, :, keep_indices, :] = pk\n",
    "    values[:, :, keep_indices, :] = pv\n",
    "    return keys, values\n",
    "\n",
    "def np_palu_compress(tensor, rank_ratio=0.25):\n",
    "    \"\"\"CPU Palu SVD (numpy baseline).\"\"\"\n",
    "    fp32 = tensor.astype(np.float32)\n",
    "    L, H, S, D = fp32.shape\n",
    "    rank = max(1, int(min(S, D) * rank_ratio))\n",
    "    all_US = []\n",
    "    all_Vt = []\n",
    "    for l in range(L):\n",
    "        for h in range(H):\n",
    "            mat = fp32[l, h]\n",
    "            U, s, Vt = np.linalg.svd(mat, full_matrices=False)\n",
    "            US = U[:, :rank] * s[None, :rank]\n",
    "            all_US.append(US.astype(np.float16))\n",
    "            all_Vt.append(Vt[:rank, :].astype(np.float16))\n",
    "    return all_US, all_Vt, list(tensor.shape), rank\n",
    "\n",
    "def np_palu_decompress(all_US, all_Vt, original_shape, rank):\n",
    "    L, H, S, D = original_shape\n",
    "    result = np.zeros(original_shape, dtype=np.float32)\n",
    "    idx = 0\n",
    "    for l in range(L):\n",
    "        for h in range(H):\n",
    "            result[l, h] = all_US[idx].astype(np.float32) @ all_Vt[idx].astype(np.float32)\n",
    "            idx += 1\n",
    "    return result.astype(np.float16)\n",
    "\n",
    "print(\"CPU numpy compressors defined (all 7).\")"
   ],
   "id": "cell-10",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Timing Utilities\n",
    "\n",
    "Key difference from v1: **CUDA Event timing** measures only GPU kernel execution.\n",
    "Data is pre-loaded to GPU before timing starts."
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Timing utilities\n",
    "\n",
    "def gpu_time_ms(fn, *args, warmup=WARMUP, repeats=REPEATS):\n",
    "    \"\"\"Time a GPU function using CUDA Events. All args must be on GPU already.\n",
    "    Returns (median_ms, std_ms, last_result).\"\"\"\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        result = fn(*args)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(repeats):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start_event.record()\n",
    "        result = fn(*args)\n",
    "        end_event.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start_event.elapsed_time(end_event))  # ms, from CUDA\n",
    "\n",
    "    return statistics.median(times), statistics.stdev(times) if len(times) > 1 else 0.0, result\n",
    "\n",
    "\n",
    "def cpu_time_ms(fn, *args, warmup=WARMUP, repeats=REPEATS):\n",
    "    \"\"\"Time a CPU function. Returns (median_ms, std_ms, last_result).\"\"\"\n",
    "    for _ in range(warmup):\n",
    "        result = fn(*args)\n",
    "    times = []\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter_ns()\n",
    "        result = fn(*args)\n",
    "        t1 = time.perf_counter_ns()\n",
    "        times.append((t1 - t0) / 1e6)\n",
    "    return statistics.median(times), statistics.stdev(times) if len(times) > 1 else 0.0, result\n",
    "\n",
    "\n",
    "def generate_kv_gpu(num_layers, num_heads, seq_len, head_dim, seed=42):\n",
    "    \"\"\"Generate KV cache directly on GPU as float32.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shape = (num_layers, num_heads, seq_len, head_dim)\n",
    "    keys_np = rng.standard_normal(shape).astype(np.float16)\n",
    "    values_np = rng.standard_normal(shape).astype(np.float16)\n",
    "    # Move to GPU once — this is NOT timed\n",
    "    keys_gpu = torch.from_numpy(keys_np).float().to(device)\n",
    "    values_gpu = torch.from_numpy(values_np).float().to(device)\n",
    "    return keys_np, values_np, keys_gpu, values_gpu\n",
    "\n",
    "\n",
    "def transfer_ms(size_bytes, bandwidth_gbps):\n",
    "    \"\"\"Analytical transfer time.\"\"\"\n",
    "    return (size_bytes * 8) / (bandwidth_gbps * 1e6)\n",
    "\n",
    "\n",
    "print(\"Timing utilities defined.\")\n",
    "print(f\"Config: warmup={WARMUP}, repeats={REPEATS}\")"
   ],
   "id": "cell-12",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Run GPU-Native Calibration\n",
    "\n",
    "For each (model, seq_len):\n",
    "1. Generate KV cache, pre-load to GPU\n",
    "2. Time **CPU numpy** compress/decompress\n",
    "3. Time **GPU-native** compress/decompress (data already on GPU, CUDA event timing)\n",
    "4. Compute speedup factor"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: INT8 calibration — GPU-native zero-copy timing\n",
    "\n",
    "int8_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        # CPU timing (keys only for speed — symmetric for values)\n",
    "        cpu_comp_ms, _, (kq_np, ks_np) = cpu_time_ms(np_int8_compress, keys_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_int8_decompress, kq_np, ks_np)\n",
    "\n",
    "        # GPU-native timing (data already on GPU, CUDA event timing)\n",
    "        gpu_comp_ms, gpu_comp_std, (kq_gpu, ks_gpu) = gpu_time_ms(gpu_int8_compress, keys_gpu)\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_int8_decompress, kq_gpu, ks_gpu)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        int8_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        # Free GPU memory\n",
    "        del keys_gpu, vals_gpu, kq_gpu, ks_gpu\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(int8_results)} INT8 calibration runs.\")"
   ],
   "id": "cell-14",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: KIVI 2-bit calibration — GPU-native zero-copy timing\n",
    "\n",
    "kivi_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        # CPU timing\n",
    "        cpu_k_ms, _, (kq, ks, kz) = cpu_time_ms(np_kivi_compress_keys, keys_np)\n",
    "        cpu_v_ms, _, (vq, vs, vz) = cpu_time_ms(np_kivi_compress_values, vals_np)\n",
    "        cpu_comp_ms = cpu_k_ms + cpu_v_ms\n",
    "\n",
    "        cpu_dk_ms, _, _ = cpu_time_ms(np_kivi_decompress_keys, kq, ks, kz)\n",
    "        cpu_dv_ms, _, _ = cpu_time_ms(np_kivi_decompress_values, vq, vs, vz)\n",
    "        cpu_decomp_ms = cpu_dk_ms + cpu_dv_ms\n",
    "\n",
    "        # GPU-native timing (data already on GPU)\n",
    "        gpu_k_ms, _, (kq_g, ks_g, kz_g) = gpu_time_ms(gpu_kivi_compress_keys, keys_gpu)\n",
    "        gpu_v_ms, _, (vq_g, vs_g, vz_g) = gpu_time_ms(gpu_kivi_compress_values, vals_gpu)\n",
    "        gpu_comp_ms = gpu_k_ms + gpu_v_ms\n",
    "\n",
    "        gpu_dk_ms, _, _ = gpu_time_ms(gpu_kivi_decompress_keys, kq_g, ks_g, kz_g)\n",
    "        gpu_dv_ms, _, _ = gpu_time_ms(gpu_kivi_decompress_values, vq_g, vs_g, vz_g)\n",
    "        gpu_decomp_ms = gpu_dk_ms + gpu_dv_ms\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        kivi_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu, kq_g, ks_g, kz_g, vq_g, vs_g, vz_g\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(kivi_results)} KIVI calibration runs.\")"
   ],
   "id": "cell-15",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7b: INT4 calibration\n",
    "\n",
    "int4_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        # CPU timing\n",
    "        cpu_comp_ms, _, (kp, ks, kz, ksh) = cpu_time_ms(np_int4_compress, keys_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_int4_decompress, kp, ks, kz, ksh)\n",
    "\n",
    "        # GPU timing\n",
    "        gpu_comp_ms, gpu_comp_std, (gp, gs, gz, gsh) = gpu_time_ms(gpu_int4_compress, keys_gpu)\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_int4_decompress, gp, gs, gz, gsh)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        int4_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu, gp, gs, gz\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(int4_results)} INT4 calibration runs.\")"
   ],
   "id": "cell-16",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7c: FP8 calibration\n",
    "\n",
    "fp8_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        cpu_comp_ms, _, (kq, ks) = cpu_time_ms(np_fp8_compress, keys_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_fp8_decompress, kq, ks)\n",
    "\n",
    "        gpu_comp_ms, gpu_comp_std, (gq, gsc) = gpu_time_ms(gpu_fp8_compress, keys_gpu)\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_fp8_decompress, gq, gsc)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        fp8_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu, gq, gsc\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(fp8_results)} FP8 calibration runs.\")"
   ],
   "id": "cell-17",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7d: CacheGen calibration\n",
    "\n",
    "cachegen_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        cpu_comp_ms, _, cpu_comp_out = cpu_time_ms(np_cachegen_compress, keys_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_cachegen_decompress, *cpu_comp_out)\n",
    "\n",
    "        gpu_comp_ms, gpu_comp_std, gpu_comp_out = gpu_time_ms(gpu_cachegen_compress, keys_gpu)\n",
    "        # Unpack for decompress timing\n",
    "        a_q, a_s, a_z, dp, ds, dz, osh = gpu_comp_out\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_cachegen_decompress, a_q, a_s, a_z, dp, ds, dz, osh)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        cachegen_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu, a_q, a_s, a_z, dp, ds, dz\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(cachegen_results)} CacheGen calibration runs.\")"
   ],
   "id": "cell-18",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7e: Cascade (prune50+INT4) calibration\n",
    "\n",
    "cascade_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        cpu_comp_ms, _, cpu_out = cpu_time_ms(np_cascade_compress, keys_np, vals_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_cascade_decompress, *cpu_out)\n",
    "\n",
    "        gpu_comp_ms, gpu_comp_std, gpu_out = gpu_time_ms(gpu_cascade_compress, keys_gpu, vals_gpu)\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_cascade_decompress, *gpu_out)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        cascade_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(cascade_results)} Cascade calibration runs.\")"
   ],
   "id": "cell-19",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7f: Palu (SVD) calibration\n",
    "\n",
    "palu_results = []\n",
    "\n",
    "print(f\"{'Model':<16} {'Seq':>5} {'MB':>6}  {'CPU comp':>10} {'GPU comp':>10} {'Speedup':>8}  {'CPU dec':>10} {'GPU dec':>10} {'Speedup':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in SEQ_LENS:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        cache_mb = (keys_np.nbytes + vals_np.nbytes) / (1024 * 1024)\n",
    "\n",
    "        cpu_comp_ms, _, (c_US, c_Vt, c_sh, c_r) = cpu_time_ms(np_palu_compress, keys_np)\n",
    "        cpu_decomp_ms, _, _ = cpu_time_ms(np_palu_decompress, c_US, c_Vt, c_sh, c_r)\n",
    "\n",
    "        gpu_comp_ms, gpu_comp_std, (g_US, g_Vt, g_sh, g_r) = gpu_time_ms(gpu_palu_compress, keys_gpu)\n",
    "        gpu_decomp_ms, gpu_decomp_std, _ = gpu_time_ms(gpu_palu_decompress, g_US, g_Vt, g_sh)\n",
    "\n",
    "        comp_speedup = cpu_comp_ms / gpu_comp_ms if gpu_comp_ms > 0 else float('inf')\n",
    "        decomp_speedup = cpu_decomp_ms / gpu_decomp_ms if gpu_decomp_ms > 0 else float('inf')\n",
    "\n",
    "        entry = {\n",
    "            \"model\": model_name, \"seq_len\": seq_len, \"cache_mb\": round(cache_mb, 1),\n",
    "            \"cpu_compress_ms\": round(cpu_comp_ms, 3),\n",
    "            \"gpu_compress_ms\": round(gpu_comp_ms, 3),\n",
    "            \"gpu_compress_std_ms\": round(gpu_comp_std, 3),\n",
    "            \"compress_speedup\": round(comp_speedup, 1),\n",
    "            \"cpu_decompress_ms\": round(cpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_ms\": round(gpu_decomp_ms, 3),\n",
    "            \"gpu_decompress_std_ms\": round(gpu_decomp_std, 3),\n",
    "            \"decompress_speedup\": round(decomp_speedup, 1),\n",
    "        }\n",
    "        palu_results.append(entry)\n",
    "\n",
    "        print(f\"{model_name:<16} {seq_len:>5} {cache_mb:>5.0f}M  \"\n",
    "              f\"{cpu_comp_ms:>8.2f}ms {gpu_comp_ms:>8.2f}ms {comp_speedup:>7.1f}x  \"\n",
    "              f\"{cpu_decomp_ms:>8.2f}ms {gpu_decomp_ms:>8.2f}ms {decomp_speedup:>7.1f}x\")\n",
    "\n",
    "        del keys_gpu, vals_gpu, g_US, g_Vt\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nCompleted {len(palu_results)} Palu calibration runs.\")"
   ],
   "id": "cell-20",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Pipeline Comparison (Sequential vs Pipelined)\n",
    "\n",
    "Using **GPU-native kernel times** to model realistic end-to-end latency."
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 8: Pipeline comparison with GPU-native timing (all 7 compressors)\n",
    "\n",
    "pipeline_results = []\n",
    "\n",
    "# Compression ratio map (approximate, for transfer size estimation)\n",
    "COMP_RATIOS = {\n",
    "    \"uniform_int8\": 2.0,\n",
    "    \"kivi_2bit\": 7.0,\n",
    "    \"uniform_int4\": 4.0,\n",
    "    \"fp8_e4m3\": 2.0,\n",
    "    \"cachegen\": 3.8,\n",
    "    \"cascade_prune50_int4\": 8.0,\n",
    "    \"palu_lr\": 4.0,\n",
    "}\n",
    "\n",
    "for model_name, (num_layers, num_heads, head_dim) in MODELS.items():\n",
    "    for seq_len in [512, 1024, 2048]:\n",
    "        keys_np, vals_np, keys_gpu, vals_gpu = generate_kv_gpu(num_layers, num_heads, seq_len, head_dim)\n",
    "        original_bytes = keys_np.nbytes + vals_np.nbytes\n",
    "\n",
    "        for comp_name in COMP_RATIOS:\n",
    "            ratio = COMP_RATIOS[comp_name]\n",
    "            compressed_bytes = int(original_bytes / ratio)\n",
    "\n",
    "            # Measure GPU compress time\n",
    "            if comp_name == \"uniform_int8\":\n",
    "                comp_ms_k, _, _ = gpu_time_ms(gpu_int8_compress, keys_gpu, warmup=3, repeats=10)\n",
    "                comp_ms_v, _, _ = gpu_time_ms(gpu_int8_compress, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = comp_ms_k + comp_ms_v\n",
    "                kq, ks = gpu_int8_compress(keys_gpu)\n",
    "                vq, vs_ = gpu_int8_compress(vals_gpu)\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_int8_decompress, kq, ks, warmup=3, repeats=10)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_int8_decompress, vq, vs_, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del kq, ks, vq, vs_\n",
    "\n",
    "            elif comp_name == \"kivi_2bit\":\n",
    "                comp_ms_k, _, _ = gpu_time_ms(gpu_kivi_compress_keys, keys_gpu, warmup=3, repeats=10)\n",
    "                comp_ms_v, _, _ = gpu_time_ms(gpu_kivi_compress_values, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = comp_ms_k + comp_ms_v\n",
    "                kq, ks, kz = gpu_kivi_compress_keys(keys_gpu)\n",
    "                vq, vs_, vz = gpu_kivi_compress_values(vals_gpu)\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_kivi_decompress_keys, kq, ks, kz, warmup=3, repeats=10)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_kivi_decompress_values, vq, vs_, vz, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del kq, ks, kz, vq, vs_, vz\n",
    "\n",
    "            elif comp_name == \"uniform_int4\":\n",
    "                comp_ms_k, _, _ = gpu_time_ms(gpu_int4_compress, keys_gpu, warmup=3, repeats=10)\n",
    "                comp_ms_v, _, _ = gpu_time_ms(gpu_int4_compress, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = comp_ms_k + comp_ms_v\n",
    "                gp, gs, gz, gsh = gpu_int4_compress(keys_gpu)\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_int4_decompress, gp, gs, gz, gsh, warmup=3, repeats=10)\n",
    "                gp2, gs2, gz2, gsh2 = gpu_int4_compress(vals_gpu)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_int4_decompress, gp2, gs2, gz2, gsh2, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del gp, gs, gz, gp2, gs2, gz2\n",
    "\n",
    "            elif comp_name == \"fp8_e4m3\":\n",
    "                comp_ms_k, _, _ = gpu_time_ms(gpu_fp8_compress, keys_gpu, warmup=3, repeats=10)\n",
    "                comp_ms_v, _, _ = gpu_time_ms(gpu_fp8_compress, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = comp_ms_k + comp_ms_v\n",
    "                gq, gsc = gpu_fp8_compress(keys_gpu)\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_fp8_decompress, gq, gsc, warmup=3, repeats=10)\n",
    "                gq2, gsc2 = gpu_fp8_compress(vals_gpu)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_fp8_decompress, gq2, gsc2, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del gq, gsc, gq2, gsc2\n",
    "\n",
    "            elif comp_name == \"cachegen\":\n",
    "                full_comp_ms_k, _, comp_out_k = gpu_time_ms(gpu_cachegen_compress, keys_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms_v, _, comp_out_v = gpu_time_ms(gpu_cachegen_compress, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = full_comp_ms_k + full_comp_ms_v\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_cachegen_decompress, *comp_out_k, warmup=3, repeats=10)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_cachegen_decompress, *comp_out_v, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del comp_out_k, comp_out_v\n",
    "\n",
    "            elif comp_name == \"cascade_prune50_int4\":\n",
    "                full_comp_ms, _, comp_out = gpu_time_ms(gpu_cascade_compress, keys_gpu, vals_gpu, warmup=3, repeats=10)\n",
    "                full_decomp_ms, _, _ = gpu_time_ms(gpu_cascade_decompress, *comp_out, warmup=3, repeats=10)\n",
    "                del comp_out\n",
    "\n",
    "            elif comp_name == \"palu_lr\":\n",
    "                comp_ms_k, _, (g_US, g_Vt, g_sh, g_r) = gpu_time_ms(gpu_palu_compress, keys_gpu, warmup=3, repeats=10)\n",
    "                comp_ms_v, _, (g_US2, g_Vt2, g_sh2, g_r2) = gpu_time_ms(gpu_palu_compress, vals_gpu, warmup=3, repeats=10)\n",
    "                full_comp_ms = comp_ms_k + comp_ms_v\n",
    "                dec_k, _, _ = gpu_time_ms(gpu_palu_decompress, g_US, g_Vt, g_sh, warmup=3, repeats=10)\n",
    "                dec_v, _, _ = gpu_time_ms(gpu_palu_decompress, g_US2, g_Vt2, g_sh2, warmup=3, repeats=10)\n",
    "                full_decomp_ms = dec_k + dec_v\n",
    "                del g_US, g_Vt, g_US2, g_Vt2\n",
    "\n",
    "            for bw in BANDWIDTHS_GBPS:\n",
    "                raw_ms = transfer_ms(original_bytes, bw)\n",
    "                xfer_ms = transfer_ms(compressed_bytes, bw)\n",
    "\n",
    "                seq_total = full_comp_ms + xfer_ms + full_decomp_ms\n",
    "                seq_speedup = raw_ms / seq_total if seq_total > 0 else float('inf')\n",
    "\n",
    "                n = num_layers\n",
    "                comp_c = full_comp_ms / n\n",
    "                xfer_c = xfer_ms / n\n",
    "                dec_c = full_decomp_ms / n\n",
    "                bottleneck = max(comp_c, xfer_c, dec_c)\n",
    "                pipe_total = (comp_c + xfer_c + dec_c) + (n - 1) * bottleneck\n",
    "                pipe_speedup = raw_ms / pipe_total if pipe_total > 0 else float('inf')\n",
    "                saving = (seq_total - pipe_total) / seq_total * 100 if seq_total > 0 else 0\n",
    "                bn_name = \"compress\" if comp_c >= max(xfer_c, dec_c) else (\"transfer\" if xfer_c >= dec_c else \"decompress\")\n",
    "\n",
    "                pipeline_results.append({\n",
    "                    \"model\": model_name, \"seq_len\": seq_len, \"compressor\": comp_name,\n",
    "                    \"bandwidth_gbps\": bw,\n",
    "                    \"gpu_compress_ms\": round(full_comp_ms, 4),\n",
    "                    \"gpu_decompress_ms\": round(full_decomp_ms, 4),\n",
    "                    \"transfer_ms\": round(xfer_ms, 4),\n",
    "                    \"raw_transfer_ms\": round(raw_ms, 4),\n",
    "                    \"sequential_total_ms\": round(seq_total, 4),\n",
    "                    \"sequential_speedup\": round(seq_speedup, 4),\n",
    "                    \"pipelined_total_ms\": round(pipe_total, 4),\n",
    "                    \"pipelined_speedup\": round(pipe_speedup, 4),\n",
    "                    \"pipeline_saving_pct\": round(saving, 1),\n",
    "                    \"bottleneck_stage\": bn_name,\n",
    "                })\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        del keys_gpu, vals_gpu\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Completed {len(pipeline_results)} pipeline runs.\")\n",
    "\n",
    "print(f\"\\n{'Compressor':<25} {'BW':>6} {'Seq Speed':>10} {'Pipe Speed':>10} {'BN':>12}\")\n",
    "print(\"-\" * 70)\n",
    "for e in pipeline_results:\n",
    "    if e[\"seq_len\"] == 1024 and e[\"model\"] == \"llama-3.1-8b\" and e[\"bandwidth_gbps\"] in [10, 50, 100]:\n",
    "        print(f\"{e['compressor']:<25} {e['bandwidth_gbps']:>5}G \"\n",
    "              f\"{e['sequential_speedup']:>9.2f}x {e['pipelined_speedup']:>9.2f}x \"\n",
    "              f\"{e['bottleneck_stage']:>12}\")"
   ],
   "id": "cell-22",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Results Summary"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Summary (all 7 compressors)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GPU-NATIVE CALIBRATION RESULTS (Zero-Copy, CUDA Event Timing)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"Timing: torch.cuda.Event (microsecond precision, no CPU\\u2194GPU copies)\")\n",
    "\n",
    "ALL_CAL = [\n",
    "    (\"uniform_int8\", int8_results),\n",
    "    (\"kivi_2bit\", kivi_results),\n",
    "    (\"uniform_int4\", int4_results),\n",
    "    (\"fp8_e4m3\", fp8_results),\n",
    "    (\"cachegen\", cachegen_results),\n",
    "    (\"cascade_prune50_int4\", cascade_results),\n",
    "    (\"palu_lr\", palu_results),\n",
    "]\n",
    "\n",
    "for name, results in ALL_CAL:\n",
    "    comp_sp = [e[\"compress_speedup\"] for e in results]\n",
    "    dec_sp = [e[\"decompress_speedup\"] for e in results]\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"  Compress:   mean={np.mean(comp_sp):.1f}x, range=[{min(comp_sp):.1f}x, {max(comp_sp):.1f}x]\")\n",
    "    print(f\"  Decompress: mean={np.mean(dec_sp):.1f}x, range=[{min(dec_sp):.1f}x, {max(dec_sp):.1f}x]\")\n",
    "\n",
    "# Pipeline\n",
    "pipe_savings = [e[\"pipeline_saving_pct\"] for e in pipeline_results]\n",
    "print(f\"\\n--- Pipeline Savings (all compressors) ---\")\n",
    "print(f\"  Mean: {np.mean(pipe_savings):.1f}%, Range: [{min(pipe_savings):.1f}%, {max(pipe_savings):.1f}%]\")\n",
    "\n",
    "# Break-even\n",
    "print(f\"\\n--- Break-Even Bandwidth (seq=1024, llama-3.1-8b) ---\")\n",
    "for comp_name in COMP_RATIOS:\n",
    "    entries = sorted(\n",
    "        [e for e in pipeline_results if e[\"compressor\"] == comp_name and e[\"model\"] == \"llama-3.1-8b\" and e[\"seq_len\"] == 1024],\n",
    "        key=lambda e: e[\"bandwidth_gbps\"]\n",
    "    )\n",
    "    seq_be = pipe_be = \"N/A\"\n",
    "    for e in entries:\n",
    "        if e[\"sequential_speedup\"] > 1.0 and seq_be == \"N/A\":\n",
    "            seq_be = f\"{e['bandwidth_gbps']}G\"\n",
    "        if e[\"pipelined_speedup\"] > 1.0 and pipe_be == \"N/A\":\n",
    "            pipe_be = f\"{e['bandwidth_gbps']}G\"\n",
    "    print(f\"  {comp_name}: sequential={seq_be}, pipelined={pipe_be}\")"
   ],
   "id": "cell-24",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Publication figures\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({\"font.size\": 12, \"figure.dpi\": 150})\n",
    "\n",
    "# Figure 1: CPU vs GPU compress time (log scale)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, (results, title) in enumerate([(int8_results, \"Uniform INT8\"), (kivi_results, \"KIVI 2-bit\")]):\n",
    "    ax = axes[idx]\n",
    "    for model_name in MODELS:\n",
    "        data = [e for e in results if e[\"model\"] == model_name]\n",
    "        sls = [e[\"seq_len\"] for e in data]\n",
    "        cpu = [e[\"cpu_compress_ms\"] for e in data]\n",
    "        gpu = [e[\"gpu_compress_ms\"] for e in data]\n",
    "        ax.plot(sls, cpu, \"--o\", label=f\"{model_name} (CPU)\", alpha=0.7)\n",
    "        ax.plot(sls, gpu, \"-s\", label=f\"{model_name} (GPU)\", alpha=0.7)\n",
    "    ax.set_xlabel(\"Sequence Length\")\n",
    "    ax.set_ylabel(\"Compress Time (ms)\")\n",
    "    ax.set_title(f\"{title}: CPU vs CUDA (zero-copy)\")\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f\"GPU-Native Compression Timing — {gpu_name}\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_cpu_vs_gpu_timing_v2.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "id": "cell-25",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 11: Figure 2 — Speedup curves\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "target_model = \"llama-3.1-8b\"\n",
    "target_seq = 1024\n",
    "\n",
    "for idx, comp_name in enumerate([\"uniform_int8\", \"kivi_2bit\"]):\n",
    "    ax = axes[idx]\n",
    "    data = [e for e in pipeline_results\n",
    "            if e[\"compressor\"] == comp_name and e[\"model\"] == target_model and e[\"seq_len\"] == target_seq]\n",
    "    bws = [e[\"bandwidth_gbps\"] for e in data]\n",
    "    seq_s = [e[\"sequential_speedup\"] for e in data]\n",
    "    pipe_s = [e[\"pipelined_speedup\"] for e in data]\n",
    "\n",
    "    ax.semilogx(bws, seq_s, \"-o\", label=\"Sequential\", linewidth=2, markersize=8)\n",
    "    ax.semilogx(bws, pipe_s, \"-s\", label=\"Pipelined\", linewidth=2, markersize=8)\n",
    "    ax.axhline(y=1.0, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Break-even\")\n",
    "    ax.set_xlabel(\"Bandwidth (Gbps)\")\n",
    "    ax.set_ylabel(\"Speedup vs Raw Transfer\")\n",
    "    ax.set_title(f\"{comp_name} ({target_model}, seq={target_seq})\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.suptitle(f\"GPU-Calibrated Speedup (Zero-Copy) — {gpu_name}\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_gpu_speedup_curves_v2.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "id": "cell-26",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 12: Figure 3 — Speedup comparison bar chart\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "bw_targets = [1, 5, 10, 25, 50, 100]\n",
    "bar_data = {}\n",
    "\n",
    "for comp_name in [\"uniform_int8\", \"kivi_2bit\"]:\n",
    "    for bw in bw_targets:\n",
    "        key = f\"{comp_name}\\n{bw}G\"\n",
    "        pipe_s = [e[\"pipelined_speedup\"] for e in pipeline_results\n",
    "                  if e[\"compressor\"] == comp_name and e[\"bandwidth_gbps\"] == bw and e[\"seq_len\"] == 1024]\n",
    "        seq_s = [e[\"sequential_speedup\"] for e in pipeline_results\n",
    "                 if e[\"compressor\"] == comp_name and e[\"bandwidth_gbps\"] == bw and e[\"seq_len\"] == 1024]\n",
    "        if pipe_s:\n",
    "            bar_data[key] = {\"sequential\": np.mean(seq_s), \"pipelined\": np.mean(pipe_s)}\n",
    "\n",
    "x = np.arange(len(bar_data))\n",
    "w = 0.35\n",
    "seq_v = [v[\"sequential\"] for v in bar_data.values()]\n",
    "pipe_v = [v[\"pipelined\"] for v in bar_data.values()]\n",
    "\n",
    "b1 = ax.bar(x - w/2, seq_v, w, label=\"Sequential\", alpha=0.8, color=\"steelblue\")\n",
    "b2 = ax.bar(x + w/2, pipe_v, w, label=\"Pipelined\", alpha=0.8, color=\"darkorange\")\n",
    "\n",
    "ax.set_ylabel(\"Speedup vs Raw Transfer\")\n",
    "ax.set_title(f\"GPU-Native Speedup (seq=1024, avg across models) — {gpu_name}\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bar_data.keys(), fontsize=9)\n",
    "ax.legend()\n",
    "ax.axhline(y=1.0, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=2)\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "for bar in b1:\n",
    "    if bar.get_height() > 0.05:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "                f\"{bar.get_height():.1f}x\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "for bar in b2:\n",
    "    if bar.get_height() > 0.05:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
    "                f\"{bar.get_height():.1f}x\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_gpu_speedup_bars_v2.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "id": "cell-27",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 13: LaTeX tables (all 7 compressors)\n",
    "\n",
    "ALL_CAL_LATEX = [\n",
    "    (\"int8_calibration\", \"uniform\\\\_int8\", int8_results),\n",
    "    (\"kivi_calibration\", \"kivi\\\\_2bit\", kivi_results),\n",
    "    (\"int4_calibration\", \"uniform\\\\_int4\", int4_results),\n",
    "    (\"fp8_calibration\", \"fp8\\\\_e4m3\", fp8_results),\n",
    "    (\"cachegen_calibration\", \"cachegen\", cachegen_results),\n",
    "    (\"cascade_calibration\", \"cascade\\\\_prune50\\\\_int4\", cascade_results),\n",
    "    (\"palu_calibration\", \"palu\\\\_lr\", palu_results),\n",
    "]\n",
    "\n",
    "print(\"% === GPU Calibration Table ===\")\n",
    "print(\"\\\\begin{table*}[t]\")\n",
    "print(\"\\\\centering\")\n",
    "print(\"\\\\caption{GPU-native compression timing (zero-copy, CUDA events) on \" + gpu_name.replace('_', '\\\\_') + \"}\")\n",
    "print(\"\\\\label{tab:gpu_calibration}\")\n",
    "print(\"\\\\begin{tabular}{llrrrr}\")\n",
    "print(\"\\\\toprule\")\n",
    "print(\"Compressor & Model & Seq Len & CPU (ms) & GPU (ms) & Speedup \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "for _, cname, results in ALL_CAL_LATEX:\n",
    "    for e in results:\n",
    "        if e[\"seq_len\"] in [512, 1024, 2048]:\n",
    "            m = e['model'].replace('_', '\\\\_')\n",
    "            print(f\"  {cname} & {m} & {e['seq_len']} & {e['cpu_compress_ms']:.2f} & {e['gpu_compress_ms']:.3f} & {e['compress_speedup']:.0f}$\\\\times$ \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular}\")\n",
    "print(\"\\\\end{table*}\")\n",
    "\n",
    "print(\"\\n% === Break-Even Table ===\")\n",
    "print(\"\\\\begin{table}[t]\")\n",
    "print(\"\\\\centering\")\n",
    "print(\"\\\\caption{GPU-calibrated break-even bandwidth (lowest Gbps where speedup $> 1$)}\")\n",
    "print(\"\\\\label{tab:gpu_breakeven}\")\n",
    "print(\"\\\\begin{tabular}{llcc}\")\n",
    "print(\"\\\\toprule\")\n",
    "print(\"Strategy & Model & Sequential & Pipelined \\\\\\\\\")\n",
    "print(\"\\\\midrule\")\n",
    "for cn in COMP_RATIOS:\n",
    "    for mn in MODELS:\n",
    "        entries = sorted([e for e in pipeline_results if e[\"compressor\"]==cn and e[\"model\"]==mn and e[\"seq_len\"]==1024], key=lambda e: e[\"bandwidth_gbps\"])\n",
    "        sbe = pbe = \"N/A\"\n",
    "        for e in entries:\n",
    "            if e[\"sequential_speedup\"] > 1 and sbe == \"N/A\": sbe = f\"{e['bandwidth_gbps']}G\"\n",
    "            if e[\"pipelined_speedup\"] > 1 and pbe == \"N/A\": pbe = f\"{e['bandwidth_gbps']}G\"\n",
    "        c = cn.replace('_','\\\\_')\n",
    "        m = mn.replace('_','\\\\_')\n",
    "        print(f\"  {c} & {m} & {sbe} & {pbe} \\\\\\\\\")\n",
    "print(\"\\\\bottomrule\")\n",
    "print(\"\\\\end{tabular}\")\n",
    "print(\"\\\\end{table}\")"
   ],
   "id": "cell-28",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 14: Save all results (all 7 compressors)\n\nALL_CAL_SAVE = {\n    \"int8\": int8_results,\n    \"kivi\": kivi_results,\n    \"int4\": int4_results,\n    \"fp8\": fp8_results,\n    \"cachegen\": cachegen_results,\n    \"cascade\": cascade_results,\n    \"palu\": palu_results,\n}\n\n# Build summary stats for each compressor\nsummary_dict = {}\nfor short_name, results in ALL_CAL_SAVE.items():\n    comp_sp = [e[\"compress_speedup\"] for e in results]\n    dec_sp = [e[\"decompress_speedup\"] for e in results]\n    summary_dict[f\"{short_name}_compress_speedup_mean\"] = round(float(np.mean(comp_sp)), 1)\n    summary_dict[f\"{short_name}_compress_speedup_range\"] = [round(float(min(comp_sp)), 1), round(float(max(comp_sp)), 1)]\n    summary_dict[f\"{short_name}_decompress_speedup_mean\"] = round(float(np.mean(dec_sp)), 1)\n    summary_dict[f\"{short_name}_decompress_speedup_range\"] = [round(float(min(dec_sp)), 1), round(float(max(dec_sp)), 1)]\n\npipe_savings = [e[\"pipeline_saving_pct\"] for e in pipeline_results]\nsummary_dict[\"pipeline_saving_mean_pct\"] = round(float(np.mean(pipe_savings)), 1)\nsummary_dict[\"pipeline_saving_range_pct\"] = [round(float(min(pipe_savings)), 1), round(float(max(pipe_savings)), 1)]\n\nall_results = {\n    \"metadata\": {\n        \"gpu\": gpu_name,\n        \"gpu_tier\": GPU_TIER,\n        \"gpu_info\": gpu_info,\n        \"pytorch_version\": torch.__version__,\n        \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n        \"timing_method\": \"torch.cuda.Event (zero-copy, GPU-native)\",\n        \"fp8_path\": FP8_PATH,\n        \"version\": \"v3_all_compressors\",\n        \"models\": {k: {\"layers\": v[0], \"kv_heads\": v[1], \"head_dim\": v[2]} for k, v in MODELS.items()},\n        \"seq_lens\": SEQ_LENS,\n        \"warmup\": WARMUP,\n        \"repeats\": REPEATS,\n    },\n    \"int8_calibration\": int8_results,\n    \"kivi_calibration\": kivi_results,\n    \"int4_calibration\": int4_results,\n    \"fp8_calibration\": fp8_results,\n    \"cachegen_calibration\": cachegen_results,\n    \"cascade_calibration\": cascade_results,\n    \"palu_calibration\": palu_results,\n    \"pipeline_comparison\": pipeline_results,\n    \"summary\": summary_dict,\n}\n\nout_filename = f\"gpu_calibration_results_{GPU_TIER}.json\"\nwith open(out_filename, \"w\") as f:\n    json.dump(all_results, f, indent=2)\n\nprint(f\"Saved: {out_filename}\")\nprint(f\"  GPU: {gpu_name} (tier={GPU_TIER})\")\nprint(f\"  GPU info: {json.dumps(gpu_info, indent=2)}\")\nprint(f\"  FP8 path: {FP8_PATH}\")\nprint(f\"  - {len(int8_results)} INT8 + {len(kivi_results)} KIVI + {len(int4_results)} INT4\")\nprint(f\"  - {len(fp8_results)} FP8 + {len(cachegen_results)} CacheGen\")\nprint(f\"  - {len(cascade_results)} Cascade + {len(palu_results)} Palu\")\nprint(f\"  - {len(pipeline_results)} pipeline entries\")\nprint(f\"\\nDone! Download {out_filename} for your paper.\")",
   "id": "cell-29",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Changed from v2\n",
    "\n",
    "| Aspect | v2 (2 compressors) | v3 (all 7 compressors) |\n",
    "|--------|-------------------|----------------------|\n",
    "| Compressors | INT8, KIVI 2-bit | + INT4, FP8, CacheGen, Cascade, Palu |\n",
    "| Pipeline comparison | 2 strategies | 7 strategies |\n",
    "| JSON sections | int8, kivi calibration | + int4, fp8, cachegen, cascade, palu |\n",
    "| Paper Table 1 | 2 GPU rows filled | All 7 GPU rows filled |\n",
    "| Runtime | ~5-10 min | ~15-25 min (SVD is compute-heavy) |\n",
    "\n",
    "### Notes\n",
    "- **Palu (SVD)**: Expect modest 2-5x GPU speedup since SVD is already well-parallelized via LAPACK on CPU\n",
    "- **Cascade**: Includes `torch.topk` sorting cost in timing (realistic)\n",
    "- **CacheGen**: Most complex — chunked delta pattern is fully vectorized on GPU"
   ],
   "id": "cell-30"
  },
  {
   "cell_type": "markdown",
   "source": "## Multi-GPU Comparison\n\nAfter running this notebook on multiple GPU tiers (T4, A100, H100), combine the results\nusing the integration script:\n\n```bash\n# Integrate T4 baseline with additional GPU results\npython experiments/scripts/integrate_gpu_calibration.py \\\n    experiments/results/model_sweep/results.json \\\n    experiments/notebooks/gpu_calibration_results_t4.json \\\n    --gpu-results experiments/notebooks/gpu_calibration_results_a100.json \\\n                  experiments/notebooks/gpu_calibration_results_h100.json\n```\n\nThis produces multi-GPU comparison figures in `paper/figures/gpu_calibrated/` including:\n- **Break-even bandwidth shift** across GPU tiers\n- **Speedup comparison** bars per compressor per GPU\n- **Pipeline saving** differences (faster GPUs → higher break-even bandwidth)\n\nThe visualization functions `plot_multi_gpu_speedup()` and `plot_breakeven_shift()` in\n`kvshuttle/visualization/gpu_calibration.py` handle the rendering automatically.",
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}